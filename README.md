# Multimodal Emotion Detection System

A lightweight, easy-to-use emotion detection system that predicts emotions from either **text**, **image**, or **audio** input â€” all handled via a simple **Streamlit web app**.

ğŸŒ **Live Demo**: [https://multimodalemotiondetection.streamlit.app/](https://multimodalemotiondetection.streamlit.app/)

---

## ğŸš€ Features

- ğŸ“„ **Text Emotion Detection** â€“ Uses DistilBERT to detect emotions from sentences.
- ğŸ–¼ï¸ **Image Emotion Detection** â€“ Uses a custom-trained ShuffleNet model on facial expression images.
- ğŸ¤ **Audio Emotion Detection** â€“ Uses Wav2Vec2 model to classify emotion from audio clips.
- ğŸ“¦ **Streamlit UI** â€“ Upload interface for text, image, and audio.

> âš ï¸ **Note:** Live camera and audio recording features are not yet implemented â€” only file upload is currently supported.

---

## ğŸ” Use Cases

- Customer feedback sentiment analysis
- Emotion detection for healthcare/chatbots
- Social media content analysis

---

## ğŸ§  Models Used

| Modality | Model         | Source                                     |
| -------- | ------------- | ------------------------------------------ |
| Text     | DistilBERT    | HuggingFace Transformers                   |
| Image    | ShuffleNet V2 | Custom trained on FER+ dataset             |
| Audio    | Wav2Vec2      | Fine-tuned from pre-trained Facebook model |

---

## ğŸ“ Project Structure

```
multimodal_emotion_detection/
â”œâ”€â”€ app.py                         # Streamlit app
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ text_emotion_model/       # DistilBERT tokenizer + weights
â”‚   â””â”€â”€ image_emotion_model/      # ShuffleNet image model (shufflenet_fast.pth)
â”œâ”€â”€ text_model/
â”‚   â””â”€â”€ train_text_model.py       # Text model training script
â”œâ”€â”€ predict_text.py               # Text prediction logic
â”œâ”€â”€ predict_image_only.py         # Image prediction logic
â”œâ”€â”€ predict_multimodal.py         # Combined inference (not used in current version)
â”œâ”€â”€ requirements.txt              # Dependencies
â””â”€â”€ README.md                     # Project info
```

---

## ğŸ› ï¸ Setup Instructions

1. **Clone the repo**:

```bash
git clone https://github.com/Vankudoth-Saipriya/multimodal_emotion_detection.git
cd multimodal_emotion_detection
```

2. **Install dependencies**:

```bash
pip install -r requirements.txt
```

3. **Run Streamlit App**:

```bash
streamlit run app.py
```

---

## ğŸ¯ Future Improvements

- âœ… Add webcam-based image detection
- âœ… Add real-time microphone recording for audio
- â³ Add sentiment fusion model (text + image + audio)
- ğŸŒ Mobile responsiveness

---

## ğŸ“¦ Deployment

- App is deployed on **Streamlit Cloud**.
- Requirements are auto-installed from `requirements.txt`.
- Model weights are loaded from GitHub (Git LFS enabled).

---

## ğŸ™Œ Acknowledgments

- HuggingFace ğŸ¤— for pretrained models
- PyTorch and TorchVision
- Streamlit for UI simplicity
- FER+ dataset for image emotion training

---

## ğŸ‘¤ Author

**Sai Priya Vankudoth**

- [GitHub](https://github.com/Vankudoth-Saipriya)

---

## ğŸ“Œ License

This project is under the MIT License.

