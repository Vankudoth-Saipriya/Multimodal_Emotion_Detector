ğŸ­ Multimodal Emotion Detection

An intelligent emotion detection system capable of analyzing text, image, and audio inputs to detect human emotions with high accuracy using deep learning models.

ğŸŒ Live Demo: https://multimodalemotiondetection.streamlit.app/

ğŸ“Œ Features

ğŸ“„ Text Emotion Detection: Uses a fine-tuned DistilBERT model to classify emotions from text.

ğŸ–¼ï¸ Image Emotion Detection: Utilizes a CNN-based ShuffleNet model trained on facial expressions.

ğŸ”Š Audio Emotion Detection: Employs Wav2Vec2.0 model for speech-based emotion recognition.

ğŸ“ Simple UI: Upload audio (WAV), text, or image files to see real-time predictions.

ğŸ§  Multimodal: Works on three modalities independently, allowing flexibility in user input.

ğŸ“‚ Project Structure

multimodal_emotion_detection/
â”œâ”€â”€ app.py                            # Main Streamlit app
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ image_emotion_model/
â”‚   â”‚   â””â”€â”€ shufflenet_fast.pth      # Trained CNN model
â”‚   â””â”€â”€ text_emotion_model/
â”‚       â”œâ”€â”€ config.json
â”‚       â”œâ”€â”€ model.safetensors
â”‚       â”œâ”€â”€ tokenizer_config.json
â”‚       â”œâ”€â”€ vocab.txt
â”‚       â””â”€â”€ ...
â”œâ”€â”€ predict_image_only.py            # Standalone image prediction script
â”œâ”€â”€ predict_text.py                  # Standalone text prediction script
â”œâ”€â”€ predict_multimodal.py           # Old multimodal (optional)
â”œâ”€â”€ text_model/
â”‚   â””â”€â”€ train_text_model.py          # Script to train text model
â””â”€â”€ train_image_model.py             # Script to train image model

ğŸš€ Quick Start

ğŸ–¥ï¸ Run Locally

Clone the Repository

git clone https://github.com/Vankudoth-Saipriya/multimodal_emotion_detection.git
cd multimodal_emotion_detection

Install Requirements

pip install -r requirements.txt

Launch App

streamlit run app.py

ğŸ› ï¸ Models Used

Modality

Model

Description

Text

DistilBERT

Fine-tuned for 6 emotion categories

Image

ShuffleNet Fast

Lightweight CNN trained on facial datasets

Audio

Wav2Vec2.0 (HuggingFace)

Emotion classification from raw waveform

ğŸ“… Usage (on Web App)

Text Tab

Paste or type text â†’ Click "Predict Emotion"

Image Tab

Upload .jpg or .png file â†’ See predicted emotion

Audio Tab

Upload .wav file â†’ Audio gets classified

ğŸ“ Future Improvements

ğŸ”´ Add webcam capture for real-time facial emotion detection.

ğŸ”´ Add real-time audio recording for voice emotion input.

ğŸŸ¡ Expand datasets and refine model accuracies.

ğŸŸ¢ Integrate combined (fused) multimodal prediction pipeline.

ğŸ”µ Enable deployment on HuggingFace Spaces / Docker.

ğŸ“¦ Requirements

All dependencies are listed in requirements.txt. Major ones:

streamlit
torch
transformers
torchaudio
Pillow
opencv-python
librosa

ğŸ‘©â€ğŸ’¼ Author

Sai Priya Vankudoth

ğŸŒ GitHub: @Vankudoth-Saipriya

ğŸ§ª License

This project is licensed under the MIT License â€” see the LICENSE file for details.

